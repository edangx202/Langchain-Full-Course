{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "This new feature proves beneficial in a wide array of situations. It can assist in designing chatbots capable of interacting with various APIs, facilitate task automation, and enable extraction of organized information from inputs expressed in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (0.0.205)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.9 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (0.0.11)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: openai in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain\n",
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you got the AT LEAST Version 0.0.200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of the langchain library is 0.0.205.\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "\n",
    "def print_version(package_name):\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package_name).version\n",
    "        print(f\"The version of the {package_name} library is {version}.\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"The {package_name} library is not installed.\")\n",
    "\n",
    "\n",
    "print_version(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to define a function. This one mimics a database query with a \"fake\" price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pizza_info(pizza_name: str):\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return json.dumps(pizza_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_pizza_info\",\n",
    "        \"description\": \"Get name and price of a pizza of the restaurant\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pizza_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the pizza, e.g. Salami\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"pizza_name\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        functions=functions,\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7f9a7c1e0410> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"The capital of France is Paris.\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7f9a7c1e0590> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"name\": \"get_pizza_info\",\n",
       "    \"arguments\": \"{\\n  \\\"pizza_name\\\": \\\"Salami\\\"\\n}\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7T7228SvEQrwMjuamTr9Y0x1n4z75 at 0x7f9a8ed93410> JSON: {\n",
       "  \"id\": \"chatcmpl-7T7228SvEQrwMjuamTr9Y0x1n4z75\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687172898,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The cost of a pizza salami is $10.99.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 59,\n",
       "    \"completion_tokens\": 13,\n",
       "    \"total_tokens\": 72\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if message.get(\"function_call\"):\n",
    "    function_name = message[\"function_call\"][\"name\"]\n",
    "    pizza_name = json.loads(message[\"function_call\"][\"arguments\"]).get(\"pizza_name\")\n",
    "    function_response = get_pizza_info(\n",
    "        pizza_name=pizza_name\n",
    "    )\n",
    "\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            message,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "second_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain \n",
    "\n",
    "LangChain allows you to use functions too, but currently (15.06.2023) it is kind of hacky to do it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "message = llm.predict_messages(\n",
    "    [HumanMessage(content=\"What is the capital of france?\")], functions=functions\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_pizza_info', 'arguments': '{\\n\"pizza_name\": \"Salami\"\\n}'}}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much does Pizza Salami cost in the restaurant?\"\n",
    "message_pizza = llm.predict_messages([HumanMessage(content=query)], functions=functions)\n",
    "message_pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'get_pizza_info',\n",
       "  'arguments': '{\\n\"pizza_name\": \"Salami\"\\n}'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_pizza.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salami'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "pizza_name = json.loads(message_pizza.additional_kwargs[\"function_call\"][\"arguments\"]).get(\"pizza_name\")\n",
    "pizza_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Salami\", \"price\": \"10.99\"}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza_api_response = get_pizza_info(pizza_name=pizza_name)\n",
    "pizza_api_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Pizza Salami costs $10.99 in the restaurant.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "second_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=query),\n",
    "        AIMessage(content=str(message_pizza.additional_kwargs)),\n",
    "        ChatMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": message_pizza.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=pizza_api_response\n",
    "        ),\n",
    "    ],\n",
    "    functions=functions,\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tools\n",
    "\n",
    "You can convert Tools to functions, both the Tools provided by langchain and also your own tools. The Tool you see is there to show you the interface of a tool, it actually does nothing really do anything useful ;-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "\n",
    "class StupidJokeTool(BaseTool):\n",
    "    name = \"StupidJokeTool\"\n",
    "    description = \"Tool to explain jokes about chickens\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        return \"It is funny, because AI...\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"joke tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StupidJokeTool',\n",
       "  'description': 'Tool to explain jokes about chickens',\n",
       "  'parameters': {'properties': {'__arg1': {'title': '__arg1',\n",
       "     'type': 'string'}},\n",
       "   'required': ['__arg1'],\n",
       "   'type': 'object'}},\n",
       " {'name': 'move_file',\n",
       "  'description': 'Move or rename a file from one location to another',\n",
       "  'parameters': {'title': 'FileMoveInput',\n",
       "   'description': 'Input for MoveFileTool.',\n",
       "   'type': 'object',\n",
       "   'properties': {'source_path': {'title': 'Source Path',\n",
       "     'description': 'Path of the file to move',\n",
       "     'type': 'string'},\n",
       "    'destination_path': {'title': 'Destination Path',\n",
       "     'description': 'New path for the moved file',\n",
       "     'type': 'string'}},\n",
       "   'required': ['source_path', 'destination_path']}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import format_tool_to_openai_function, MoveFileTool\n",
    "\n",
    "\n",
    "tools = [StupidJokeTool(), MoveFileTool()]\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'StupidJokeTool', 'arguments': '{\\n  \"__arg1\": \"To get to the other side\"\\n}'}}, example=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Why does the chicken cross the road? To get to the other side\"\n",
    "output = llm.predict_messages([HumanMessage(content=query)], functions=functions)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is funny, because AI...'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = json.loads(output.additional_kwargs[\"function_call\"][\"arguments\"]).get(\"__arg1\")\n",
    "tool_response = tools[0].run(question)\n",
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The chicken crosses the road to get to the other side.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=query),\n",
    "        AIMessage(content=str(output.additional_kwargs)),\n",
    "        ChatMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": output.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=\"\"\"\n",
    "                {tool_response}\n",
    "            \"\"\",\n",
    "        ),\n",
    "    ],\n",
    "    functions=functions,\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Functions Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe capital of France is Paris.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `100 / 25`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "100 / 25\u001b[32;1m\u001b[1;3m```text\n",
      "100 / 25\n",
      "```\n",
      "...numexpr.evaluate(\"100 / 25\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m4.0\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAnswer: 4.0\u001b[0m\u001b[32;1m\u001b[1;3m100 divided by 25 is equal to 4.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'100 divided by 25 is equal to 4.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is 100 devided by 25?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
